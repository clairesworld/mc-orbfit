{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from analyze_orbits.ipynb\n"
     ]
    }
   ],
   "source": [
    "%run ../tools/autoipy.py\n",
    "\n",
    "from analyze_orbits import get_orbits\n",
    "# from matplotlib.ticker import FormatStrFormatter\n",
    "import collections\n",
    "import numpy as np\n",
    "import math\n",
    "import emcee\n",
    "import pickle\n",
    "import os\n",
    "import traceback\n",
    "from profilestats import profile\n",
    "from pathlib import Path\n",
    "from scipy.stats import rayleigh\n",
    "from scipy.stats import beta\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# FIXED VALUES\n",
    "\n",
    "mass_sun=1 # solar mass\n",
    "mass_pl=1 # earth mass\n",
    "\n",
    "mass_sun_kg = 1.989e30\n",
    "mass_earth_kg = 5.972e24\n",
    "G_const = 6.67408e-11\n",
    "mu_earth = G_const * (mass_sun_kg + mass_earth_kg)\n",
    "AU2m = 1.496e11\n",
    "\n",
    "f_disp_e = 0.081 # dispersion parameter for ecc distribution\n",
    "C_norm_e = ( 1 - np.exp(-1/(2*f_disp_e**2)) )**-1\n",
    "\n",
    "\n",
    "lna_min = np.log(0.1) \n",
    "lna_max = np.log(50)\n",
    "\n",
    "# lna_min = np.log(0.2) \n",
    "# lna_max = np.log(1.71)\n",
    "\n",
    "beta_a = 0.867 # kipping 2013 http://adsabs.harvard.edu/cgi-bin/bib_query?arXiv:1306.4982\n",
    "beta_b = 3.03\n",
    "\n",
    "\n",
    "lna_min_true = np.log(0.95) #lna_max_true = np.log(1.70) \n",
    "lna_max_true = np.log(1.70) #lna_min_true = np.log(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     4,
     20,
     58
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# emcee functions for Rayleigh distribution\n",
    "\n",
    "from numpy import log, array, pi, inf, exp, sqrt\n",
    "\n",
    "def lnprior_Ray(theta):\n",
    "    # The parameters are stored as a vector of values, so unpack them\n",
    "    lna, cosi, ecc, omega_p, xi_0, lan = theta\n",
    "    \n",
    "    # let eccentricity be flat for now\n",
    "    if not (lna_min < lna < lna_max) or not (-1 < cosi < 1) or not (0 < omega_p < 2*pi) or not (0 < xi_0 < 2*pi) or not (0 < lan < 2*pi):\n",
    "        return -inf\n",
    "    if not (0 <= ecc < 1): # bounds of rayleigh distribution\n",
    "        return -inf\n",
    "     \n",
    "    \n",
    "    lnPr_ecc = log(C_norm_e*ecc/f_disp_e**2) - ecc**2/(2*f_disp_e**2) # rayleigh distribution for ecc prior\n",
    "\n",
    "    return lnPr_ecc  # this is normalized (area under pdf = 1)\n",
    "\n",
    "\n",
    "def lnlike(theta, x, y, aproj, s, cadence, n_epochs, i_det, i_nondet, a_IWA):\n",
    "    # fitting aproj(xi) with several measurements of aproj given as a list\n",
    "    \n",
    "    x_model, y_model, aproj_model = obv_at_epoch(theta, range(n_epochs), cadence, noise=False)  \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        false_nondet_model = [(aproj_model[i] > a_IWA) for i in i_nondet] \n",
    "        reject = any(false_nondet_model) \n",
    "    except IndexError: # first epoch\n",
    "        false_nondet_model = ((aproj_model > a_IWA) and (0 in i_nondet))\n",
    "        reject = false_nondet_model \n",
    "     \n",
    "    if reject: # any model predictions are outside IWA for nondetection epochs\n",
    "#         print('rejecting aproj_model', aproj_model, 'with i_nondet', i_nondet)\n",
    "        return -inf\n",
    "\n",
    "    ll_nondet = 0 \n",
    "#     n_nondet_model = len(i_nondet) # number of correct nondetections in model is necessarily all of them\n",
    "#     ll_nondet = -n_nondet_model * log(a_IWA - exp(lna_min))\n",
    "    \n",
    "\n",
    "    # only fit params with aproj > IWA\n",
    "    X = [x[i] for i in i_det]\n",
    "    Y = [y[i] for i in i_det]\n",
    "    \n",
    "    try:\n",
    "        X_model = [x_model[i] for i in i_det]\n",
    "        Y_model = [y_model[i] for i in i_det]\n",
    "    except IndexError: # if first epoch\n",
    "        X_model = [[x_model][i] for i in i_det]\n",
    "        Y_model = [[y_model][i] for i in i_det]\n",
    "        \n",
    "    chi2 =  np.sum(  ( ( array(X) - array(X_model) )**2 + ( array(Y) - array(Y_model) )**2 )/(s**2) )\n",
    "    ll_det = -chi2 - len(i_det)*( log(pi) + 2*log(s) )\n",
    "    \n",
    "    return  ll_det + ll_nondet    # ln likelihood\n",
    "\n",
    "def lnprob_Ray(theta, x, y, aproj, s, cadence, n_epochs, i_det, i_nondet, a_IWA):\n",
    "   \n",
    "    lp = lnprior_Ray(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -inf\n",
    "    \n",
    "    ll = lnlike(theta, x, y, aproj, s, cadence, n_epochs, i_det, i_nondet,  a_IWA)\n",
    "    if not np.isfinite(ll):\n",
    "        return -inf\n",
    "    \n",
    "    return lp + ll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     2,
     13
    ]
   },
   "outputs": [],
   "source": [
    "# emcee functions for uniform eccentricity dist\n",
    "\n",
    "def lnprior_uni(theta):\n",
    "    # The parameters are stored as a vector of values, so unpack them\n",
    "    lna, cosi, ecc, omega_p, xi_0, lan = theta\n",
    "    \n",
    "    # let eccentricity be flat for now\n",
    "    if not (0 <= ecc < 1) or not (lna_min < lna < lna_max) or not (-1 < cosi < 1) or not (0 < omega_p < 2*np.pi) or not (0 < xi_0 < 2*np.pi) or not (0 < lan < 2*np.pi):\n",
    "        return -np.inf\n",
    "    return 0.0\n",
    "    \n",
    "\n",
    "\n",
    "def lnprob_uni(theta, x, y, aproj, s, cadence, n_epochs, i_det, i_nondet, a_IWA):\n",
    "   \n",
    "    lp = lnprior_uni(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -inf\n",
    "    \n",
    "    ll = lnlike(theta, x, y, aproj, s, cadence, n_epochs, i_det, i_nondet,  a_IWA)\n",
    "    if not np.isfinite(ll):\n",
    "        return -inf\n",
    "    \n",
    "    return lp + ll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     5,
     22
    ]
   },
   "outputs": [],
   "source": [
    "# emcee functions for beta distribution\n",
    "from scipy.special import gamma\n",
    "gamma_ab = gamma(beta_a + beta_b)\n",
    "gamma_a = gamma(beta_a)\n",
    "gamma_b = gamma(beta_b)\n",
    "def lnprior_Beta(theta):\n",
    "    # The parameters are stored as a vector of values, so unpack them\n",
    "    lna, cosi, ecc, omega_p, xi_0, lan = theta\n",
    "    \n",
    "    # let eccentricity be flat for now\n",
    "    if not (lna_min < lna < lna_max) or not (-1 < cosi < 1) or not (0 < omega_p < 2*pi) or not (0 < xi_0 < 2*pi) or not (0 < lan < 2*pi):\n",
    "        return -inf\n",
    "#     if not (0 <= ecc < 1): # bounds of rayleigh distribution\n",
    "#         return -inf\n",
    "     \n",
    "\n",
    "    lnPr_ecc = log(( gamma_ab * ecc**(beta_a-1) * (1-ecc)**(beta_b-1) ) / (gamma_a * gamma_b) )\n",
    "   \n",
    "    return lnPr_ecc  # this is normalized (area under pdf = 1)\n",
    "\n",
    "\n",
    "\n",
    "def lnprob_Beta(theta, x, y, aproj, s, cadence, n_epochs, i_det, i_nondet, a_IWA):\n",
    "   \n",
    "    lp = lnprior_Beta(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -inf\n",
    "    \n",
    "    ll = lnlike(theta, x, y, aproj, s, cadence, n_epochs, i_det, i_nondet,  a_IWA)\n",
    "    if not np.isfinite(ll):\n",
    "        return -inf\n",
    "    \n",
    "    return lp + ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# from analyze_orbits import read_obvs\n",
    "\n",
    "# theta = [ 1.17472559,  0.35798731,  0.35423964,  1.87096859,  0.37901581,  3.65733168]\n",
    "# x, y, aproj = read_obvs('data/90day_nov28')[8]\n",
    "# x = x[:2]\n",
    "# y=y[:2]\n",
    "# aproj=aproj[:2]\n",
    "# cadence=90\n",
    "# n_epochs=5\n",
    "# IWA = 3 * 500e-9/10 * 206265 # arcsec\n",
    "# OWA = 10 * 500e-9/10 * 206265 # arcsec\n",
    "# d=10\n",
    "# s = d*(5*1e-3) # convert mas error to AU\n",
    "# a_IWA = d*IWA\n",
    "# i_nondet = []\n",
    "# i_det = [0, 1]\n",
    "\n",
    "# lnprob = lnprob_Beta(theta, x, y, aproj, s, cadence, n_epochs, i_det, i_nondet, a_IWA)\n",
    "# ll = lnlike(theta, x, y, aproj, s, cadence, n_epochs, i_det, i_nondet,  a_IWA)\n",
    "# print('ln prob', lnprob)\n",
    "# print('ln likelihood', ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0,
     2
    ]
   },
   "outputs": [],
   "source": [
    "# emcee functions for circular orbits - fitting only 4 variables\n",
    "\n",
    "def lnprior_circ(theta):\n",
    "    # The parameters are stored as a vector of values, so unpack them\n",
    "    lna, cosi, xi_0, lan = theta\n",
    "    \n",
    "    if not (lna_min < lna < lna_max) or not (-1 < cosi < 1)  or not (0 < xi_0 < 2*np.pi) or not (0 < lan < 2*np.pi):\n",
    "        return -np.inf\n",
    "    return 0\n",
    "\n",
    "\n",
    "def lnprob_circ(theta, x, y, aproj, s, cadence, n_epochs, i_det, i_nondet,  a_IWA):\n",
    "    lp = lnprior_circ(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    ll = lnlike(theta, x, y, aproj, s, cadence, n_epochs, i_det, i_nondet,  a_IWA)\n",
    "    return lp + ll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0,
     7
    ]
   },
   "outputs": [],
   "source": [
    "def read_truths(direc):\n",
    "    cwd = os.getcwd()\n",
    "    f = open(str(cwd)+'/'+direc+'/truths_iters.dat', 'rb')\n",
    "    s = pickle.load(f)  # variables come out in the order you put them in\n",
    "    f.close()\n",
    "    return s\n",
    "\n",
    "def read_obvs(direc):\n",
    "    cwd = os.getcwd()\n",
    "    f = open(str(cwd)+'/'+direc+'/obvs_iters.dat', 'rb')\n",
    "    s = pickle.load(f)  # variables come out in the order you put them in\n",
    "    f.close()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0,
     36
    ]
   },
   "outputs": [],
   "source": [
    "def obv_at_epoch(truths, n_epoch, cadence=None, s_AU=0.01, noise=False): \n",
    "    \n",
    "    try:\n",
    "        lna, cosi, ecc, omega_p, xi_0, lan = truths\n",
    "    except: # circular orbits, 4 vars\n",
    "        lna, cosi, xi_0, lan = truths\n",
    "        ecc=0\n",
    "        omega_p=0\n",
    "        \n",
    "    \n",
    "    a = exp(lna)\n",
    "    b = a*sqrt(1-ecc**2)\n",
    "    c = sqrt(a**2 - b**2) # ellipse\n",
    "\n",
    "    if n_epoch==0:\n",
    "        xi = xi_0\n",
    "    else:\n",
    "#         calculate xi: assume that planet has been moving on Keplerian orbit given delta t, sma posterior\n",
    "#         the phase the planet would be observed at this epoch given these parameters\n",
    "        xi = getNextPhase(n_epoch, cadence, a, xi_0)\n",
    "\n",
    "    alpha = lan #lan\n",
    "    beta = np.arccos(cosi)\n",
    "    gamma = omega_p\n",
    "    t = xi\n",
    "    x, y, _ = EuclideanRotation(alpha, beta, gamma, a, b, t) # this takes iterables for t\n",
    "    \n",
    "    if noise:\n",
    "        x, y = np.random.normal(loc=[x, y], scale=s_AU/sqrt(2))   \n",
    "\n",
    "    # calculate euclidean distance \n",
    "    aproj = sqrt(x**2 + (y**2))\n",
    "\n",
    "    return x, y, aproj\n",
    "\n",
    "from math import sin, cos\n",
    "def EuclideanRotation(alpha, beta, gamma, a, b, t):\n",
    "        # t can be an iterable\n",
    "    c = sqrt(a**2 - b**2) # ellipse\n",
    "    try:\n",
    "        v = np.array([[a*cos(t) - c],[b*sin(t)],[0]]) # column vector of points\n",
    "    except TypeError: \n",
    "        v = np.array([[a*np.cos(t) - c],[b*np.sin(t)],[0]]) # column vector of points\n",
    "    cA = cos(alpha)\n",
    "    cB = cos(beta)\n",
    "    cC = cos(gamma)\n",
    "    \n",
    "    sA = sin(alpha)\n",
    "    sB = sin(beta)\n",
    "    sC = sin(gamma)\n",
    "    \n",
    "    R = np.array([[cA*cC - cB*sA*sC, -cC*sA-cA*cB*sC, sB*sC],\n",
    "                 [cB*cC*sA + cA*sC, cA*cB*cC - sA*sC, -cC*sB],\n",
    "                 [sA*sB, cA*sB, cB]])\n",
    "    \n",
    "#     R = np.array([[np.cos(beta), -np.cos(gamma)*np.sin(beta), np.sin(beta)*np.sin(gamma)], \n",
    "#                   [np.cos(alpha)*np.sin(beta), np.cos(alpha)*np.cos(beta)*np.cos(gamma)-(np.sin(alpha)*np.sin(gamma)), -np.cos(gamma)*np.sin(alpha)-(np.cos(alpha)*np.cos(beta)*np.sin(gamma))],\n",
    "#                   [np.sin(alpha)*np.sin(beta), np.cos(alpha)*np.sin(gamma)+(np.cos(beta)*np.cos(gamma)*np.sin(alpha)), np.cos(alpha)*np.cos(gamma)-(np.cos(beta)*np.sin(alpha)*np.sin(gamma))]])\n",
    "    \n",
    "    L_rot = np.dot(R, v)\n",
    "    x = L_rot[0]\n",
    "    y = L_rot[1]\n",
    "    z = L_rot[2]\n",
    "    return x[0], y[0], z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true 0.831481967234\n",
      "0.831704410816\n",
      "0.0356001032434\n",
      "range 0.219919731975\n",
      "0.955725525915\n",
      "0.73580579394\n"
     ]
    }
   ],
   "source": [
    "# truths = [np.log(1.0), np.cos(1.08312938748), 0.378364330327, 1.70787590579, 2.13710086603, 1.66472380962]\n",
    "# aproj_= []\n",
    "# _, _, aproj_true = obv_at_epoch(truths, 0, 90, noise=False)\n",
    "# for ii in range(1000):\n",
    "#     _, _, aproj = obv_at_epoch(truths, 0, 90, s_AU=0.05, noise=True)\n",
    "#     aproj_.append(aproj)\n",
    "    \n",
    "# print('true', aproj_true)\n",
    "# print(np.mean(aproj_))\n",
    "# print(np.std(aproj_))\n",
    "# print('range', np.max(aproj_) - np.min(aproj_))\n",
    "# print(np.max(aproj_))\n",
    "# print(np.min(aproj_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# alt functions for emcee where all orbits are circular\n",
    "\n",
    "def lnprior_circular(theta):\n",
    "    # The parameters are stored as a vector of values, so unpack them\n",
    "    lna, cosi, omega_p, xi_0 = theta\n",
    "    \n",
    "    # let eccentricity be flat for now\n",
    "    if not (lna_min < lna < lna_max) or not (0 < cosi < 1) or not (0 < omega_p < 2*np.pi) or not (0 < xi_0 < 2*np.pi):\n",
    "        return -np.inf\n",
    "\n",
    "    return 0 \n",
    "\n",
    "def lnlike_circular(theta, aproj, s, cadence):\n",
    "    # fitting aproj(xi) with several measurements of aproj given as a list\n",
    "    \n",
    "    #lna, cosi, ecc, omega_p, xi = theta\n",
    "    #model = aproj(ecc, np.exp(lna), np.arccos(cosi), xi, omega_p) # returns a_proj\n",
    "    lna, cosi, omega_p, xi_0 = theta\n",
    "    n_epochs = len(aproj)\n",
    "    el = np.zeros(n_epochs) # chi sqr terms to be summed\n",
    "    # get error for each aproj measurement\n",
    "#     for n in range(n_epochs):\n",
    "#         expected = aproj_at_epoch(ecc, np.exp(lna), np.arccos(cosi), omega_p, xi_0, n, cadence) # returns a_proj\n",
    "#         el[n] = ( aproj[n] - expected )**2 / (2*s**2)\n",
    "    expected = aproj_at_epoch(0, np.exp(lna), np.arccos(cosi), omega_p, xi_0, range(n_epochs), cadence) # returns a_proj\n",
    "    el = ( np.array(aproj) - np.array(expected) )**2 / (2*s**2)\n",
    "    return -np.sum(el)\n",
    "    \n",
    "    #return -0.5*(np.sum( ((aproj-model)/s)**2. ))\n",
    "\n",
    "def lnprob_circular(theta, aproj, s, n_epoch, cadence):\n",
    "    lp = lnprior_circular(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + lnlike_circular(theta, aproj, s, cadence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     153,
     250
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'analyze_orbits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-58ae1d6c26b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0manalyze_orbits\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmaxlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_chain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'analyze_orbits'"
     ]
    }
   ],
   "source": [
    "# functions for running\n",
    "import json\n",
    "import scipy.optimize as op\n",
    "from analyze_orbits import maxlikelihood, plot_chain, read_results\n",
    "\n",
    "\n",
    "# @profile(print_stats=10, sort_stats='time')\n",
    "def run_epochs(n_epochs_tot, truths, obvs, s, cadence, nwalkers=100, saveall=False, ecc_dist='Rayleigh',\n",
    "               fname='samples', progress=True, chainlength=1e5, a_IWA=None, ep_start=0, d=None, it_start=0,\n",
    "               i_it=None, direc=None, show_autocorr=False, show_chainplot=False, \n",
    "               initialize='ML', analytic=False):\n",
    "   \n",
    "    # loops over each epoch to get their posteriors, each set of samples represents the cumulative information over the preceeding epochs\n",
    "    # cadence: days, s: measurement error, pos, nwalkers from emcee\n",
    "    cwd = os.getcwd()\n",
    "    ndim = len(truths)\n",
    "    samples_epochs = [] # mcmc output will be stored here\n",
    "    lnprob_epochs = []\n",
    "    chains_epochs = []\n",
    "    flatchains_epochs=[]\n",
    "    ML_epochs = []\n",
    "    std_ep = []\n",
    "    mean_ep =[]\n",
    "\n",
    "    if ecc_dist=='circular':\n",
    "        lna_true, cosi_true, xi_0_true, lan_true = truths\n",
    "    #         ecc_true=0\n",
    "    #         omega_p_true=0\n",
    "        pos_min = np.array([lna_min, 0., 0., 0.])\n",
    "        pos_max = np.array([lna_max, 1., 2*np.pi, 2*np.pi])        \n",
    "\n",
    "    else:\n",
    "        lna_true, cosi_true, ecc_true, omega_p_true, xi_0_true, lan_true = truths\n",
    "#         pos_min = np.array([lna_min, 0., 0., 0., 0., 0.])\n",
    "#         pos_max = np.array([lna_max, 1., 1., np.pi, np.pi, np.pi])\n",
    "        pos_min = np.array([lna_min, -1., 0., 0., 0., 0.])\n",
    "        pos_max = np.array([lna_max, 1., 1., 2*np.pi, 2*np.pi, 2*np.pi])\n",
    "\n",
    "#     psize = pos_max - pos_min\n",
    "#     pmedian = np.median([pos_min, pos_max], axis=0)\n",
    "    pmedian = [-0.53647227,  0.5,   0.0001,  1.57079633,  1.57079633,  1.57079633]\n",
    "    psize = pos_max - pos_min\n",
    "    \n",
    "    x_true=[]\n",
    "    y_true=[]\n",
    "    aproj_true = [] # list of a_proj observations\n",
    "    i_det=[]\n",
    "    i_nondet=[]\n",
    "    \n",
    "    x_eps, y_eps, aproj_eps = obvs # unpack - these have added noise\n",
    "    \n",
    "    for n in range(n_epochs_tot):\n",
    "        print('\\n\\n\\n     epoch',n,'/',n_epochs_tot)\n",
    "        x_clean, y_clean, aproj_clean =  obv_at_epoch(truths, n_epoch=n, cadence=cadence, s_AU=s, noise=False)  \n",
    "        x = x_eps[n]\n",
    "        y = y_eps[n]\n",
    "        aproj = aproj_eps[n]\n",
    "        x_true.append(x)\n",
    "        y_true.append(y)\n",
    "        aproj_true.append(aproj)\n",
    "        print('          (x, y, aproj) noisy =', x, y, aproj)\n",
    "        print('          (x, y, aproj) clean =', x_clean, y_clean, aproj_clean)\n",
    "\n",
    "\n",
    "        if aproj > a_IWA:\n",
    "            i_det.append(n)\n",
    "            det_text = 'detection'\n",
    "        else:\n",
    "            i_nondet.append(n)\n",
    "            det_text = 'nondetection'\n",
    "        print('          '+det_text)\n",
    "\n",
    "   \n",
    "        if n >= ep_start: # so you can just fit the three epochs at the end etc\n",
    "            print('\\n          truths', truths[0:3])\n",
    "            if n >= 3:\n",
    "                k = nwalkers\n",
    "                steps = chainlength\n",
    "            elif (n < 2) and analytic:\n",
    "                k=13\n",
    "                steps = 1050\n",
    "            elif (n==0) and (ep_start==0):\n",
    "                # first epoch\n",
    "                k = nwalkers*2\n",
    "                steps = chainlength*10\n",
    "            else:\n",
    "                # double walkers for epoch 3\n",
    "                k = nwalkers*2\n",
    "                steps = chainlength\n",
    "            \n",
    "            if ecc_dist=='Beta':\n",
    "                nll = lambda *args: -lnprob_Beta(*args)\n",
    "            elif ecc_dist=='uniform':\n",
    "                nll = lambda *args: -lnprob_uni(*args)\n",
    "            if initialize=='ML':\n",
    "                # get starting guess --> https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize\n",
    "                print('          initialize ML')\n",
    "                result = op.minimize(nll, [truths], args=(x_true, y_true, aproj_true, s, cadence, n+1, i_det, i_nondet, a_IWA))\n",
    "                theta_ml = result[\"x\"]\n",
    "    #             print('          theta_ml % error:' (theta_ml[0:3]-truths[0:3])/theta_ml[0:3])\n",
    "                pos = [result[\"x\"] + 1e-1*np.random.randn(ndim) for i in range(k)]\n",
    "            elif initialize=='aproj':\n",
    "                print('          initalize aproj')\n",
    "                inittruth = pmedian\n",
    "                inittruth[0] = aproj\n",
    "                result = op.minimize(nll, [inittruth], args=(x_true, y_true, aproj_true, s, cadence, n+1, i_det, i_nondet, a_IWA))\n",
    "                theta_ml = result[\"x\"]\n",
    "                print('          theta_ml', theta_ml[0:3])\n",
    "                pos = [result[\"x\"] + 1e-2*np.random.randn(ndim) for i in range(k)]\n",
    "            elif initialize=='random':\n",
    "                print('          initialize random')\n",
    "                pos = [pos_min + psize*np.random.rand(ndim) for i in range(k)]\n",
    "            elif initialize=='last':\n",
    "                # start with random guess for epoch 0\n",
    "                if n==ep_start:\n",
    "                    print('          initialize random')\n",
    "                    pos = [pos_min + psize*np.random.rand(ndim) for i in range(k)]\n",
    "                else:\n",
    "                    print('          initialize from last epoch -->', n-1)\n",
    "                    # retrieve last epoch's ML\n",
    "                    init = ML_new.copy()\n",
    "                    print('ML_new', ML_new)\n",
    "                    init[0] = np.log(init[0])\n",
    "                    init[1] = np.cos(init[1])\n",
    "                    print('init', init)\n",
    "                    print('ML_new', ML_new)\n",
    "                    pos = [init + 1e-1*np.random.randn(ndim) for i in range(k)]\n",
    "                    \n",
    "            else:\n",
    "                print('need initialization')\n",
    "            \n",
    "                \n",
    "            # correct for out of bounds\n",
    "            # PROBLEM: if spread of ball is too wide, and walkers are forced out of range, \n",
    "            # then u get lots of things at 0 or 1\n",
    "            for ik in range(k):\n",
    "#                 if pos[ik][0] < 0: # ln(a)\n",
    "#                     pos[ik][0] = 0\n",
    "                if pos[ik][1] < 0: # cos(i)\n",
    "                    pos[ik][1] = 0\n",
    "                elif pos[ik][1] > 1:\n",
    "                    pos[ik][1] = 1\n",
    "                if pos[ik][2] < 0: # e\n",
    "                    pos[ik][2] = 0\n",
    "                elif pos[ik][2] > 1:\n",
    "                    pos[ik][2] = 1\n",
    "       \n",
    "    \n",
    "#             pos = [truths + 1e-1*np.random.randn(ndim) for i in range(k)]\n",
    "#             print('pos', np.shape(pos))\n",
    "\n",
    "            # run shit\n",
    "         \n",
    "            if ecc_dist=='Rayleigh':\n",
    "                sampler = emcee.EnsembleSampler(k, ndim, lnprob_Ray, \n",
    "                                                args=[x_true, y_true, aproj_true, s, cadence, n+1, i_det, i_nondet, a_IWA]) \n",
    "            elif ecc_dist=='Beta':\n",
    "                sampler = emcee.EnsembleSampler(k, ndim, lnprob_Beta, \n",
    "                                                args=[x_true, y_true, aproj_true, s, cadence, n+1, i_det, i_nondet, a_IWA]) \n",
    "            elif ecc_dist=='uniform':\n",
    "                sampler = emcee.EnsembleSampler(k, ndim, lnprob_uni, \n",
    "                                                args=[x_true, y_true, aproj_true, s, cadence, n+1, i_det, i_nondet, a_IWA]) \n",
    "            elif ecc_dist=='circular':\n",
    "                sampler = emcee.EnsembleSampler(k, ndim, lnprob_circ, \n",
    "                                                args=[x_true, y_true, aproj_true, s, cadence, n+1, i_det, i_nondet, a_IWA]) \n",
    "\n",
    "\n",
    "            sampler.run_mcmc(pos, steps, progress=progress) # chain shape (n_walkers, n_steps-1000, ndim)\n",
    "            \n",
    "#             print('lnprobability shape', np.shape(sampler.lnprobability))\n",
    "#             print('lnprobability[1000:] shape', np.shape(sampler.lnprobability[1000:]))\n",
    "            \n",
    "            # store shit\n",
    "            samples = sampler.chain[:, 1000:, :].reshape((-1, ndim)) # discard first 1000 steps\n",
    "            lnprob = sampler.lnprobability\n",
    "#             print('samples id', id(samples[0,0]))\n",
    "           \n",
    "            chains = sampler.chain\n",
    "#             print('steps', steps)\n",
    "#             print('chains', np.shape(chains))\n",
    "            chains_epochs.append(chains)\n",
    "#             print('chains id', id(chains[0,0,0]))\n",
    "            \n",
    "            \n",
    "            \n",
    "            std_ep.append(np.std(samples, axis=0))\n",
    "            mean_ep.append(np.mean(samples, axis=0))\n",
    "\n",
    "            samples_epochs.append(samples)\n",
    "            lnprob_epochs.append(lnprob)\n",
    "            \n",
    "            \n",
    "            # save max likelihood fit\n",
    "            flatchain = sampler.flatchain\n",
    "            flatprob = sampler.flatlnprobability\n",
    "            \n",
    "            maxes = np.argwhere(flatprob == np.amax(flatprob))\n",
    "            print('\\n          # MLs', len(maxes))\n",
    "        \n",
    "#             print('flatchain id', id(flatchain[0,0]))\n",
    "#             print('flatchain[1]', flatchain[1])\n",
    "            \n",
    "#             flatchain0 = chains.reshape((-1, ndim),  order='F')\n",
    "#             print('flatchain0 id',id(flatchain0[0,0]))\n",
    "#             flatprob0 = lnprob.flatten()\n",
    "#             print('flatchain=flattened chain', (flatchain==flatchain0).all())\n",
    "#             print('flatprob=flattened prob', (flatprob==flatprob0).all())\n",
    "            \n",
    "\n",
    "            ML_new, lnprob, i_ML = maxlikelihood(flatchain, flatprob, \n",
    "                                                  x_true, y_true, aproj_true, s, cadence, n+1, i_det, i_nondet, a_IWA,\n",
    "                                                 returnmore=True, multiple=True,\n",
    "                                               )\n",
    "            print('\\n          ML_retrieved',lnprob,'@',i_ML)\n",
    "     \n",
    "            print('--------->theta_ML:',ML_new)\n",
    "#             print('          lnprob inputs:', ML_new, x_true, y_true, aproj_true, s, cadence, n+1, i_det, i_nondet, a_IWA)\n",
    "            print('\\n          lnprob_forward:',lnprob_Beta(ML_new, x_true, y_true, aproj_true, s, cadence, n+1, i_det, i_nondet, a_IWA))\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "#             ML_new0, lnprob0, i_ML0 = maxlikelihood(flatchain0, flatprob0, returnmore=True)\n",
    "#             print('\\n          ML0_retrieved',lnprob0,'@',i_ML0)\n",
    "     \n",
    "#             print('          theta_ML0:',ML_new0)\n",
    "        \n",
    "#             print('\\n        lnprob0_forward:',lnprob_Beta(ML_new0, x_true, y_true, aproj_true, s, cadence, n+1, i_det, i_nondet, a_IWA))\n",
    "            \n",
    "#             print('          i_ML',np.where(flatprob == lnprob))\n",
    "        \n",
    "            # need to reparameterize to match earlier \n",
    "            ML_new[0] = np.exp(ML_new[0])\n",
    "            ML_new[1] = np.arccos(ML_new[1])\n",
    "            ML_epochs.append(ML_new)\n",
    "            \n",
    "            flatchains_epochs.append(flatchain)\n",
    "                \n",
    "\n",
    "            print(\"          Mean acceptance fraction: {0:.3f}\"\n",
    "                    .format(np.mean(sampler.acceptance_fraction)))\n",
    "             \n",
    "            if show_autocorr:\n",
    "                \n",
    "                try:\n",
    "                    print(\"          Autocorrelation time: \", sampler.get_autocorr_time())\n",
    "        #                 plot_convergence(sampler, n)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "        else: \n",
    "            \n",
    "            # load previous results\n",
    "            \n",
    "           \n",
    "            try:\n",
    "                f = open(fname+'.dat', 'rb')\n",
    "                chains = pickle.load(f)  # variables come out in the order you put them in\n",
    "                f.close()\n",
    "                chains_epochs.append(chains[n])\n",
    "                \n",
    "                f = open(fname+'_lnprob.dat', 'rb')\n",
    "                lnprob = pickle.load(f)  # variables come out in the order you put them in\n",
    "                f.close()\n",
    "                lnprob_epochs.append(lnprob[n])\n",
    "            except: \n",
    "                chains_epochs.append(-99)\n",
    "                lnprob_epochs.append(-99)\n",
    "                        \n",
    "            f = open(str(cwd)+'/'+direc+'/d'+str(d)+'std'+str(i_it)+'.dat', 'rb')\n",
    "            std = pickle.load(f)  # variables come out in the order you put them in\n",
    "            f.close()\n",
    "            std_ep.append(std[n])\n",
    "            \n",
    "            f = open(str(cwd)+'/'+direc+'/d'+str(d)+'mean'+str(i_it)+'.dat', 'rb')\n",
    "            mean = pickle.load(f)  # variables come out in the order you put them in\n",
    "            f.close()\n",
    "            mean_ep.append(mean[n])\n",
    "          \n",
    "            f = open(str(cwd)+'/'+direc+'/d'+str(d)+'ML'+str(i_it)+'.dat', 'rb')\n",
    "            ML_new = pickle.load(f)  # variables come out in the order you put them in\n",
    "            f.close()\n",
    "            ML_epochs.append(ML_new)\n",
    "            \n",
    "            samples_epochs.append(-99*np.ones((int(nwalkers*chainlength), ndim)))\n",
    "    \n",
    "        print('n', n)\n",
    "        print('samples_epochs', np.shape(samples_epochs))\n",
    "        print('samples_epochs[n]', samples_epochs[n])\n",
    "    \n",
    "    #end\n",
    "    \n",
    "    if saveall:\n",
    "        print('\\n          pickling to',fname)\n",
    "        try:\n",
    "            with open(fname+'.dat', 'wb') as f:\n",
    "                pickle.dump(chains_epochs, f)\n",
    "#             with open(fname+'_lnprob.dat', 'wb') as f:\n",
    "#                 pickle.dump(lnprob_epochs, f)\n",
    "\n",
    "        except OverflowError:\n",
    "            print('too much data')\n",
    "        except MemoryError:\n",
    "            print('memory error')\n",
    "\n",
    "\n",
    "    with open(str(cwd)+'/'+direc+'/d'+str(d)+'ML'+str(i_it)+'.dat', 'wb') as f:\n",
    "        pickle.dump(ML_epochs, f) \n",
    "    with open(str(cwd)+'/'+direc+'/d'+str(d)+'std'+str(i_it)+'.dat', 'wb') as f:\n",
    "        pickle.dump(std_ep, f) \n",
    "    with open(str(cwd)+'/'+direc+'/d'+str(d)+'mean'+str(i_it)+'.dat', 'wb') as f:\n",
    "        pickle.dump(mean_ep, f)\n",
    "        \n",
    "    # get fits\n",
    "\n",
    "    get_orbits(direc, ndim, 1, n_epochs_tot, d, quantiles=[16, 50, 84], \n",
    "           i_it=i_it, ep_start=ep_start,\n",
    "           fname='fitted'+str(i_it)+'.dat', samples_epochs=samples_epochs\n",
    "              )\n",
    "    get_orbits(direc, ndim, 1, n_epochs_tot, d, quantiles=[2.5, 50, 97.5],  \n",
    "           i_it=i_it, ep_start=ep_start,\n",
    "           fname='fitted'+str(i_it)+'_95.dat', samples_epochs=samples_epochs\n",
    "              )\n",
    "\n",
    "#     print('\\n N O T    F I T T I N G\\n')\n",
    "\n",
    "    if show_chainplot:\n",
    "        for n in range(n_epochs_tot):\n",
    "            fig, ax = plot_chain(direc, i_it, n, 0, d, range(k), \n",
    "                       title='Iteration '+str(i_it)+', epoch '+str(n)+': '+det_text, \n",
    "                       sigma=1, \n",
    "                       lw=0.1, alpha=0.9)\n",
    "            fig.show()\n",
    "\n",
    "    return samples_epochs\n",
    "\n",
    "\n",
    "def run_iterations(n_iter, n_epochs_tot, s_mas, cadence, nwalkers=100, iter_start=0, direc='', \n",
    "                   saveall=False, ecc_dist='Rayleigh', ecc_dist_true='Rayleigh', \n",
    "                   D_tel=10, wl=500e-9,a_fixed=None, stem='samples_epochs', \n",
    "                   progress=True, chainlength=1e5, show_chainplot=False,analytic=False,\n",
    "                   truths_iters=None, newtruths=False, newobvs=False, overwrite=False, forcenondetect=None,\n",
    "                   d=10, ep_start=0, show_autocorr=False, force_first_detection=True, initialize='ML',\n",
    "                  n_iter_total=50):\n",
    "    \n",
    "    \n",
    "    # truths_iters is a list containing values for each iteration\n",
    "    # n_iter is a scalar\n",
    "    print('lna_min', lna_min)\n",
    "    print('lna_max', lna_max)\n",
    "    cwd = os.getcwd()\n",
    "    \n",
    "    IWA = 3 * wl/D_tel * 206265 # arcsec\n",
    "    OWA = 10 * wl/D_tel * 206265 # arcsec\n",
    "    print('distance at which a_IWA=1.7 AU :', 1.7/IWA, 'pc')\n",
    "\n",
    "    s_AU = d*(s_mas*1e-3) # convert mas error to AU\n",
    "    a_IWA = d*IWA\n",
    "\n",
    "    print(\"s_xy =\", s_AU)\n",
    "    print('a_IWA =',  a_IWA)\n",
    "    \n",
    "#     x0 = 2.5 *wl/D_tel * 206265 * d # AU\n",
    "#     b =1\n",
    "    \n",
    "#     if d==20:\n",
    "#         c = 0.000000001\n",
    "#         norm = 0.515663\n",
    "#     elif d==10:\n",
    "#         c = 0.0000000000000001\n",
    "#         norm = 0.257833\n",
    "#     elif d==5:\n",
    "#         c = 0.00000000000000000000000000000001\n",
    "#         norm = 0.128917\n",
    "\n",
    "#     f_lnlike_nondet = lambda x: np.log( 1 / (1 + b*c**(x0-np.array(x)))  /  norm )\n",
    "    \n",
    "    \n",
    "    if len(direc) > 0:\n",
    "        if not os.path.exists(direc):\n",
    "            os.makedirs(direc)\n",
    "            \n",
    "    if (truths_iters is None):\n",
    "        truths_file = Path(direc+'/truths_iters.dat')\n",
    "        if not newtruths:\n",
    "            if truths_file.exists():\n",
    "                truths_iters = read_truths(direc)\n",
    "                print('\\nreading truths file from ',direc)\n",
    "                if not newobvs:\n",
    "                    obvs_iters = read_obvs(direc)\n",
    "                    print('\\nreading obvs file from ',direc)\n",
    "                \n",
    "            else:\n",
    "                print('\\nnew truths?')\n",
    "                return(None)\n",
    "        else:\n",
    "            if truths_file.exists() and (not overwrite):\n",
    "                print('\\nWARNING: truths file exists, to overwrite set overwrite=True')\n",
    "                return(None)\n",
    "            else:\n",
    "                print('\\ngenerating new truths for',n_iter,'iteration(s)')\n",
    "                truths_iters, obvs_iters = get_random_orbit(n_iter_total,\n",
    "                                                            cadence=cadence, s_xy = s_AU, \n",
    "                                                 ecc_dist_true=ecc_dist_true, a_IWA=a_IWA,\n",
    "                                                a_fixed=a_fixed, i_miss=forcenondetect, \n",
    "                                                            force_first_detection=force_first_detection,\n",
    "                                                           n_ep=n_epochs_tot)\n",
    "    \n",
    "    else:\n",
    "        if newtruths:\n",
    "            print('\\ntruths_iters must be None to get new truths. continuing with input truths')\n",
    "        if np.shape(truths_iters)[0] < n_iter:\n",
    "            print('\\ntoo many iterations for input truth list')\n",
    "\n",
    "    if newtruths:\n",
    "        # store truths\n",
    "        \n",
    "        with open(str(cwd)+'/'+direc+'/truths_iters.dat', 'wb') as f:\n",
    "            pickle.dump(truths_iters, f)  \n",
    "        with open(str(cwd)+'/'+direc+'/obvs_iters.dat', 'wb') as f:\n",
    "            pickle.dump(obvs_iters, f)  \n",
    "            \n",
    "    if newobvs:\n",
    "        obvs_iters=[]\n",
    "        if newtruths:\n",
    "            print('generating new obvs from new truths')\n",
    "        else:\n",
    "            print('generating new obvs from input truths for entire range')\n",
    "        for ii in range(n_iter_total):\n",
    "            obvs_iters.append(obv_at_epoch(truths_iters[ii], n_epoch=range(n_epochs_tot), cadence=cadence, \n",
    "                                       s_AU=s_AU, noise=True))\n",
    "        # store\n",
    "        with open(str(cwd)+'/'+direc+'/obvs_iters.dat', 'wb') as f:\n",
    "            pickle.dump(obvs_iters, f) \n",
    "    \n",
    "    ndim = len(truths_iters[0])\n",
    "    for ii in range(iter_start, n_iter):\n",
    "        print('\\n ///////////// ( • ᴗ•)  /////////////////////////////////')\n",
    "        print('\\n\\niteration ',ii,'/',n_iter)\n",
    "        fname='/'+direc+'/'+stem+str(ii)\n",
    "        cwd = os.getcwd()\n",
    "        samples_epochs = run_epochs(n_epochs_tot, truths_iters[ii], obvs_iters[ii], s_AU, \n",
    "                                    cadence,saveall=saveall,nwalkers=nwalkers, \n",
    "                                    fname=str(cwd)+fname, progress=progress, analytic=analytic,\n",
    "                                    chainlength=chainlength, a_IWA=a_IWA, \n",
    "                                    ep_start=ep_start, ecc_dist=ecc_dist, it_start=iter_start,\n",
    "                                    d=d, i_it=ii, show_chainplot=show_chainplot,\n",
    "                                    direc=direc, show_autocorr=show_autocorr, initialize=initialize)\n",
    "\n",
    "#         if not saveall:\n",
    "        \n",
    "    \n",
    "#         get_orbits(direc, ndim, 1, n_epochs_tot, d, quantiles=[16, 50, 84], i_it=ii,\n",
    "#                    fname='fitted'+str(ii)+'.dat', samples_epochs=samples_epochs)\n",
    "#         get_orbits(direc, ndim, 1, n_epochs_tot, d, quantiles=[2.5, 50, 97.5],  i_it=ii,\n",
    "#                    fname='fitted'+str(ii)+'_95.dat', samples_epochs=samples_epochs)\n",
    "\n",
    "\n",
    "    overwrite=False\n",
    "    return overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0,
     61
    ]
   },
   "outputs": [],
   "source": [
    "def get_random_orbit(n, s_xy, a_fixed=None,  ecc_dist_true='Rayleigh', i_miss=None, \n",
    "                     force_first_detection=True,\n",
    "                     cadence=None, a_IWA=None, n_ep=None):\n",
    "    # ecc_dist: 'linear', 'circular', 'Rayleigh'\n",
    "    # forcenondetect = (0, 1) <-- forces first two epochs to be nondetections\n",
    "    truths_iters=[]\n",
    "    obvs_iters = []\n",
    "\n",
    "    for ii in range(n): # how many planets to simulate\n",
    "        truths=randorbit(a_fixed, ecc_dist_true)\n",
    "\n",
    "        flag=False\n",
    "        flag_onlyfirst=False\n",
    "        flag_onlymiss=False\n",
    "        \n",
    "        \n",
    "        if (i_miss is not None) and force_first_detection:\n",
    "            # forcing nondetection \n",
    "            flag=True   \n",
    "            if ii==0:\n",
    "                print('forcing nondetection @', i_miss)\n",
    "                print('forcing detection at epoch 0')\n",
    "        elif i_miss is not None:\n",
    "            flag_onlymiss=True\n",
    "            if ii==0:\n",
    "                print('forcing nondetection @', i_miss)\n",
    "        elif force_first_detection:\n",
    "            flag_onlyfirst=True\n",
    "            if ii==0:\n",
    "                print('forcing detection at epoch 0')\n",
    "        else:\n",
    "            x, y, aproj = obv_at_epoch(truths, n_epoch=range(n_ep), cadence=cadence, \n",
    "                                       s_AU=s_xy, noise=True)\n",
    "            \n",
    "        while flag:\n",
    "            x, y, aproj = obv_at_epoch(truths, n_epoch=range(n_ep), cadence=cadence, \n",
    "                                       s_AU=s_xy, noise=True)\n",
    "\n",
    "            if (aproj[i_miss]<=a_IWA) and (aproj[0]>a_IWA): # nondetection @ forced and first epoch is detection\n",
    "                break\n",
    "            truths=randorbit(a_fixed, ecc_dist_true)\n",
    "         \n",
    "        while flag_onlymiss:\n",
    "            x, y, aproj = obv_at_epoch(truths, n_epoch=range(n_ep), cadence=cadence, \n",
    "                                       s_AU=s_xy, noise=True)\n",
    "            if aproj[i_miss]<=a_IWA:\n",
    "                break\n",
    "            truths=randorbit(a_fixed, ecc_dist_true)\n",
    "        \n",
    "        while flag_onlyfirst:    \n",
    "            x, y, aproj = obv_at_epoch(truths, n_epoch=range(n_ep), cadence=cadence, \n",
    "                                       s_AU=s_xy, noise=True)\n",
    "            if aproj[0]>a_IWA: # nondetection @ forced and first epoch is detection\n",
    "                break\n",
    "            truths=randorbit(a_fixed,  ecc_dist_true)\n",
    "            \n",
    "        truths_iters.append(truths) \n",
    "        obvs_iters.append((x, y, aproj))\n",
    " \n",
    "    return truths_iters, obvs_iters\n",
    "\n",
    "def randorbit(a_fixed=None, ecc_dist_true='Rayleigh'):\n",
    "    lna_true = getlnSemimajorAxis(lna_min_true, lna_max_true, a_fixed=a_fixed)\n",
    "    cosi_true = np.cos(getInclination())\n",
    "    omega_p_true, xi_0_true, lan_true = random_uniform_circle(n=3)\n",
    "    if ecc_dist_true=='circular':\n",
    "        return (lna_true, cosi_true, xi_0_true, lan_true)\n",
    "    else:\n",
    "        ecc_true = getEccentricity(ecc_dist_true) \n",
    "#     print('lna_true', lna_true)\n",
    "    return (lna_true, cosi_true, ecc_true, omega_p_true, xi_0_true, lan_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_random_orbit_given_obvs(n, s_xy, a_fixed=None, ecc_dist='Rayleigh', ecc_dist_true='Rayleigh', \n",
    "                                tol=1e-2, aproj_fixed=1,i_ep=None,\n",
    "                                 cadence=None, a_IWA=None, n_ep=None):\n",
    "    # ecc_dist: 'linear', 'circular', 'Rayleigh'\n",
    "    # forcenondetect = (0, 1) <-- forces first two epochs to be nondetections\n",
    "    truths_iters=[]\n",
    "    obvs_iters = []\n",
    "\n",
    "    for ii in range(n): # how many planets to simulate\n",
    "        truths = randorbit(a_fixed, ecc_dist, ecc_dist_true)\n",
    "        x, y, aproj = obv_at_epoch(truths, n_epoch=range(n_ep), cadence=cadence, \n",
    "                                    s_AU=s_xy, noise=True)\n",
    "        flag=False\n",
    "\n",
    "        \n",
    "        if abs(aproj[i_ep]-aproj_fixed) > tol:\n",
    "            # forcing nondetection \n",
    "            flag=True   \n",
    "            if ii==0:\n",
    "                print('forcing a_proj @', aproj_fixed)\n",
    "\n",
    "            \n",
    "        while flag:\n",
    "            x, y, aproj = obv_at_epoch(truths, n_epoch=range(n_ep), cadence=cadence, \n",
    "                                       s_AU=s_xy, noise=True)\n",
    "\n",
    "            if abs(aproj[i_ep]-aproj_fixed) < tol: # nondetection @ forced and first epoch is detection\n",
    "                break\n",
    "                \n",
    "            truths=randorbit(a_fixed, ecc_dist, ecc_dist_true)\n",
    "            truths_iters.append(truths) \n",
    "            \n",
    "        obvs_iters.append((x, y, aproj))\n",
    " \n",
    "    return truths_iters, obvs_iters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getNextPhase(n, cadence, smas, phases):\n",
    "    # this works with iterables or scalars\n",
    "    # cadence is fixed in units day\n",
    "    \n",
    "    # calculate planet speed\n",
    "    meanmotion = np.sqrt(mu_earth/(smas*AU2m)**3) # units rad/s\n",
    "    deltat = meanmotion*(np.array(n)*(cadence*86400)) # delta M\n",
    "    M_f = np.add(phases, deltat)\n",
    "\n",
    "    try:\n",
    "        newphase = float(M_f) % (2*np.pi)\n",
    "    except TypeError: \n",
    "        # M_f is iterable\n",
    "        newphase = [float(s) % (2*np.pi) for s in M_f] \n",
    "        \n",
    "        \n",
    "#     if np.size(M_f)!=1:\n",
    "#         newphase = [float(s) % (2*np.pi) for s in M_f] \n",
    "#     else:\n",
    "#         newphase = float(M_f) % (2*np.pi)\n",
    "    return newphase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     2,
     8,
     12,
     36
    ]
   },
   "outputs": [],
   "source": [
    "# generate planetary parameters\n",
    "  \n",
    "def getlnSemimajorAxis(lnmin, lnmax, a_fixed=None):\n",
    "    if a_fixed is None:\n",
    "        return np.random.uniform(low=lnmin, high=lnmax, size=None) \n",
    "    else:\n",
    "        return np.log(a_fixed)\n",
    "    \n",
    "def getInclination():\n",
    "    cosi = np.random.uniform(low=0, high=1, size=None) # uniform in cos(i)\n",
    "    return np.arccos(cosi)\n",
    "\n",
    "def getEccentricity(dist):\n",
    "    #return np.random.uniform(0, 0.5) # worst case\n",
    "    if dist=='Rayleigh':\n",
    "        sigma = 0.081\n",
    "        sigma_low = 0.01 # 90% of planets come from this\n",
    "        sigma_high=0.22 # 10% of planets come from this\n",
    "#         return rayleigh.rvs(size=None, scale=sigma)\n",
    "        return np.random.rayleigh(scale=sigma) # Shabram+ 2015\n",
    "    elif dist=='Beta':\n",
    "        from scipy.stats import beta\n",
    "        # beta dist from Hogg et al. (2010) and Kipping (2013)\n",
    "        a = 0.867 \n",
    "        b = 3.03\n",
    "        r = beta.rvs(a, b, size=1)\n",
    "        return r[0]\n",
    "    elif dist=='linear':\n",
    "        # slope of -2.18\n",
    "        # actually try slope of 1\n",
    "        return np.random.triangular(left=0, right=1, mode=0)\n",
    "    elif dist=='uniform':\n",
    "        return np.random.uniform(low=0, high=1)\n",
    "    elif dist=='circular':\n",
    "        return 0\n",
    "    \n",
    "def random_uniform_circle(n=1): \n",
    "    # uniform in linear\n",
    "    return np.random.uniform(low=0, high=np.pi, size=n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0,
     6
    ]
   },
   "outputs": [],
   "source": [
    "def auto_window(taus, c):\n",
    "    m = np.arange(len(taus)) < c * taus\n",
    "    if np.any(m):\n",
    "        return np.argmin(m)\n",
    "    return len(taus) - 1\n",
    "\n",
    "def autocorr_new(y, c=5.0):\n",
    "    f = np.zeros(y.shape[1])\n",
    "    for yy in y:\n",
    "        f += emcee.autocorr_func_1d(yy)\n",
    "    f /= len(y)\n",
    "    taus = 2.0*np.cumsum(f)-1.0\n",
    "    window = auto_window(taus, c)\n",
    "    return taus[window]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
